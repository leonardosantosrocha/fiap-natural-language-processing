{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___\n",
        "#### **Instalação dos módulos necessários**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -q nltk\n",
        "%pip install -q numpy\n",
        "%pip install -q openai\n",
        "%pip install -q pandas\n",
        "%pip install -q scikit-learn\n",
        "%pip install -q spacy\n",
        "%pip install -q unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 13.0/13.0 MB 40.5 MB/s eta 0:00:00\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "python3 -q -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Importação dos módulos necessários**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DMBI8SQtps1n"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/leonardo/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk \n",
        "import openai\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import svm\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import spacy\n",
        "import unidecode\n",
        "nltk.download(\"stopwords\")\n",
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___\n",
        "#### **Função para pré-processamento**\n",
        "\n",
        "O pré-processamento é uma etapa fundamental para garantir melhores resultados durante a modelagem do problema. Sendo assim, desenvolvemos a função **preprocessing_text** para aplicar as transformações citadas abaixo no texto.\n",
        "\n",
        "- Conversão do texto para minúsculo\n",
        "\n",
        "- Remoção de acentos, emojis, espaços em branco, LINKS, números, pontuações e espaços múltiplos do texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocessing_text(text: str) -> str:\n",
        "\n",
        "    # Converte texto para minúsculo\n",
        "    text: str = text.lower()\n",
        "\n",
        "    # Remove acentos do texto\n",
        "    text: str = unidecode.unidecode(text)\n",
        "\n",
        "    # Remove emojis do texto\n",
        "    text: str = re.sub(r\"[^\\w\\s,?!]\", \"\", text)\n",
        "    \n",
        "    # Remove espaços em branco no texto\n",
        "    text: str = text.strip()\n",
        "\n",
        "    # Remove LINKS do texto\n",
        "    text: str = re.sub(r\"http[s]?://\\S+\", \"\", text)\n",
        "\n",
        "    # Remove números do texto\n",
        "    text: str = re.sub(r\"\\d+\", \"\", text)\n",
        "    \n",
        "    # Remove pontuação do texto\n",
        "    text: str = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "\n",
        "    # Remove vários espaços em branco do texto\n",
        "    text: str = re.sub(r\"\\s{2,}\", \" \", text)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ue0nV0uVo3OZ"
      },
      "source": [
        "#### **Função para remoção de stop words**\n",
        "\n",
        "A remoção de stops words é outra etapa indispenśavel para resolução de problemas de NLP, uma vez que palavras com pouco valor semântico (artigos, pronomes, preposições, conjunções, interjeições etc) são removidas do texto. Como resultado, há uma grande diminuição no ruído das frases, além de uma grande economia computacional, visto que menos dados serão processados. Para isso, implementamos a função **remove_stop_words** com as seguintes variações:\n",
        "\n",
        "- NLTK: stopwords do pacote NLTK.\n",
        "\n",
        "- SPACY: stopwords do pacote SPACY.\n",
        "\n",
        "- ALL: combinação das stopwords dos pacotes NLTK e SPACY."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_stop_words(text: str, mode: str = \"all\") -> str:\n",
        "    \n",
        "    # Remoção de stop words do pacote NLTK\n",
        "    if mode == \"nltk\":\n",
        "        nltk_stop_words: set = set(nltk.corpus.stopwords.words(\"portuguese\"))\n",
        "        stop_words: list = list(nltk_stop_words)\n",
        "\n",
        "    # Remoção de stop words do pacote SPACY\n",
        "    elif mode == \"spacy\":\n",
        "        spacy_stop_words: set = set(nlp.Defaults.stop_words)\n",
        "        stop_words: list = list(spacy_stop_words)\n",
        "\n",
        "    # Remoção de stop words combinando os pacotes NLTK e SPACY\n",
        "    else:\n",
        "        nltk_stop_words: set = set(nltk.corpus.stopwords.words(\"portuguese\"))\n",
        "        spacy_stop_words: set = set(nlp.Defaults.stop_words)\n",
        "        stop_words: list = list(nltk_stop_words.union(spacy_stop_words))\n",
        "\n",
        "    words: list = text.split()\n",
        "    \n",
        "    words_filtered: list = [word for word in words if word not in stop_words]\n",
        "\n",
        "    text_filtered: str = \" \".join(words_filtered)\n",
        "\n",
        "    return text_filtered"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Função para vetorização**\n",
        "\n",
        "Em termos simples, o processo de vetorização consiste na conversão de textos em números. Dessa forma, os computadores conseguem interpretar os números e gerar respostas satisfatórias (ou não) para solução de um determinado problema. No contexto do projeto, desenvolvemos a função **vectorize** com três variações da técnica de vetorização:\n",
        "\n",
        "- Count Vectorizer: cada palavra é representada por um número; a cada ocorrência da palavra, o contador do número é incrementado; é um método voltado para frequência e não para importância da palavra dado um contexto.\n",
        "\n",
        "- TF: mede a frequência de uma palavra em relação ao número total de palavras do documento; por exemplo: no texto - \"Eu gosto de assistir animes e eu gosto de ler mangás\", a palavra \"gosto\" teria um peso de 0.4 (2/5), visto que existem 5 palavras (gosto, assistir, animes, ler e mangás).\n",
        "\n",
        "- TFIDF: é uma técnica que combina o TF (frequência do termo) e o IDF (frequência inversa no documento), ou seja, a técnica tende a valorizar palavras que aparecem unicamente nos documentos, logo, palavras que aparecem com frequência entre documentos tornam-se menos relevantes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vectorize(custom_ngram: int, function: str = \"count_vectorizer\") -> CountVectorizer | TfidfVectorizer:\n",
        "    \n",
        "    if function == \"count_vectorizer\":\n",
        "        vect: CountVectorizer = CountVectorizer(ngram_range=(1, custom_ngram))\n",
        "\n",
        "    elif function == \"tf\":\n",
        "        vect: TfidfVectorizer = TfidfVectorizer(ngram_range=(1, custom_ngram), use_idf=False)\n",
        "\n",
        "    else:\n",
        "        vect: TfidfVectorizer = TfidfVectorizer(ngram_range=(1, custom_ngram), use_idf=True)\n",
        "\n",
        "    return vect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Função para lemmatização**\n",
        "\n",
        "A lemmatização é uma técnica utilizada para reduzir as palavras aos seus radicais, ou seja, palavras escritas no plural ou com diferentes conjugações seriam representadas da mesma forma, por exemplo: as palavras \"sorrir\", \"sorriram\" e \"sorririam\" seriam interpretadas como \"sorrir\". Sendo assim, implementamos a função **lemmatize** com duas variações:\n",
        "\n",
        "- ALL: onde todas palavras serão lemmatizadas.\n",
        "\n",
        "- VERBS: onde apenas os verbos serão lemmatizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def lemmatize(text : str, mode : str = \"all\") -> str:\n",
        "    \n",
        "    lemmatized_text: list = list()\n",
        "\n",
        "    document = nlp(text)\n",
        "\n",
        "    for word in document:\n",
        "        if mode == \"all\":\n",
        "            lemmatized_text.append(word.lemma_)\n",
        "        else:\n",
        "            if word.pos_ == \"VERB\":\n",
        "                lemmatized_text.append(word.lemma_)\n",
        "            else:\n",
        "                lemmatized_text.append(word.text)\n",
        "    \n",
        "    return \" \".join(lemmatized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Função para treinamento, predição e avaliação**\n",
        "\n",
        "Para facilitar o processo de treinamento, predição e avaliação dos modelos, desenvolvemos a função **fit_predict_evaluate_models**. Utilizando a função, todas as ações citadas anteriormente são realizadas nos modelos DecisionTreeClassifier, LogisticRegression e Support Vector Machine. Por fim, um dicionário contendo os resultados de avaliação dos modelos são retornados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_predict_evaluate_models(x_train: pd.DataFrame, y_train: pd.DataFrame, x_test: pd.DataFrame, y_test: pd.DataFrame):\n",
        "    \n",
        "    # Ajuste dos modelos\n",
        "    decision_tree_fit: DecisionTreeClassifier = DecisionTreeClassifier(max_depth=10, min_samples_split=4, min_samples_leaf=4, criterion=\"gini\", random_state=42).fit(x_train, y_train)\n",
        "    logistic_regression_fit: LogisticRegression = LogisticRegression(C=1.0, solver=\"lbfgs\", max_iter=1000, penalty=\"l2\", random_state=42).fit(x_train, y_train)\n",
        "    svm_fit: svm = svm.SVC(C=1.0, kernel=\"rbf\", gamma=\"scale\", degree=3, random_state=42).fit(x_train, y_train)\n",
        "\n",
        "    # Predição dos modelos\n",
        "    y_pred_decision_tree = decision_tree_fit.predict(x_test)\n",
        "    y_pred_logistic_regression = logistic_regression_fit.predict(x_test)\n",
        "    y_pred_svm = svm_fit.predict(x_test)\n",
        "\n",
        "    # Cálculo de métricas dos modelos\n",
        "    decision_tree_report = classification_report(y_test, y_pred_decision_tree, output_dict=True)\n",
        "    logistic_regression_report = classification_report(y_test, y_pred_logistic_regression, output_dict=True)\n",
        "    svm_report = classification_report(y_test, y_pred_svm, output_dict=True)\n",
        "\n",
        "    # Resultados\n",
        "    result: dict = {\n",
        "        \"DECISION_TREE\" : decision_tree_report, \n",
        "        \"LOGISTIC_REGRESSION\" : logistic_regression_report,\n",
        "        \"SVM\" : svm_report\n",
        "    }\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Função para comunicação com a API da OpenAI**\n",
        "\n",
        "Para utilizar os Largue Language Models (LLMs) no desenvolvimento do projeto, desenvolvemos a função **start_client** que recebe por input o modelo, a chave de API e a endereço base do modelo que iremos utilizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def start_client(model : str, api_key : str, base_url: str = \"\"):\n",
        "    if model in [\"gpt-4\", \"gpt-4o-mini\", \"gpt-3.5-turbo\"]:\n",
        "        return openai.OpenAI(api_key=api_key)\n",
        "    else:\n",
        "        return openai.OpenAI(api_key=api_key, base_url=base_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **Função para escolha e utilização do LLM**\n",
        "\n",
        "Após autenticação na API, criamos a função **classify_text** para facilitar o teste de diferentes modelos: GPT-4, GPT-4O-MINI, GPT-3.5-TURBO e SABIA-3. Dessa forma, ganharemos tempo durante o desenvolvimento do projeto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def classify_text(client: openai, model: str, text: str):\n",
        "    \n",
        "    if model == [\"gpt-4\", \"gpt-4o-mini\", \"gpt-3.5-turbo\"]:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\" : \"system\", \"content\": \"Você é um modelo de classificação de texto no contexto de centrais telefônicas, gostaria que classificasse o texto abaixo entre as categorias: serviços de conta bancária; cartão de crédito ou cartão pré-pago; roubo ou relatório de disputa; hipotecas ou empréstimos; outros. O resultado gostaria que seguisse o template de output: {\"'\"texto\"'\": <'texto original do input'>, \"'\"categoria\"'\": <'categoria classificada pelo chatgpt'>}.\"},\n",
        "                {\"role\" : \"user\", \"content\" : f\"Texto: {text}\"}\n",
        "            ],\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    else:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\" : \"system\", \"content\": \"Você é um modelo de classificação de texto no contexto de centrais telefônicas, gostaria que classificasse o texto abaixo entre as categorias: serviços de conta bancária; cartão de crédito ou cartão pré-pago; roubo ou relatório de disputa; hipotecas ou empréstimos; outros. O resultado gostaria que seguisse o template de output: {\"'\"texto\"'\": <'texto original do input'>, \"'\"categoria\"'\": <'categoria classificada pelo chatgpt'>}.\"},\n",
        "                {\"role\" : \"user\", \"content\" : f\"Texto: {text}\"}\n",
        "            ],\n",
        "        )\n",
        "        return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___\n",
        "#### **Leitura e visualização inicial do conjunto de dados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset: pd.DataFrame = pd.read_csv(\"datasets/dataset.csv\", delimiter=\";\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_reclamacao</th>\n",
              "      <th>data_abertura</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3229299</td>\n",
              "      <td>2019-05-01T12:00:00-05:00</td>\n",
              "      <td>Hipotecas / Empréstimos</td>\n",
              "      <td>Bom dia, meu nome é xxxx xxxx e agradeço se vo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3199379</td>\n",
              "      <td>2019-04-02T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3233499</td>\n",
              "      <td>2019-05-06T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>O cartão Chase foi relatado em xx/xx/2019. No ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3180294</td>\n",
              "      <td>2019-03-14T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Em xx/xx/2018, enquanto tentava reservar um ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3224980</td>\n",
              "      <td>2019-04-27T12:00:00-05:00</td>\n",
              "      <td>Serviços de conta bancária</td>\n",
              "      <td>Meu neto me dê cheque por {$ 1600,00} Eu depos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id_reclamacao              data_abertura  \\\n",
              "0        3229299  2019-05-01T12:00:00-05:00   \n",
              "1        3199379  2019-04-02T12:00:00-05:00   \n",
              "2        3233499  2019-05-06T12:00:00-05:00   \n",
              "3        3180294  2019-03-14T12:00:00-05:00   \n",
              "4        3224980  2019-04-27T12:00:00-05:00   \n",
              "\n",
              "                             categoria  \\\n",
              "0              Hipotecas / Empréstimos   \n",
              "1  Cartão de crédito / Cartão pré-pago   \n",
              "2  Cartão de crédito / Cartão pré-pago   \n",
              "3  Cartão de crédito / Cartão pré-pago   \n",
              "4           Serviços de conta bancária   \n",
              "\n",
              "                                descricao_reclamacao  \n",
              "0  Bom dia, meu nome é xxxx xxxx e agradeço se vo...  \n",
              "1  Atualizei meu cartão xxxx xxxx em xx/xx/2018 e...  \n",
              "2  O cartão Chase foi relatado em xx/xx/2019. No ...  \n",
              "3  Em xx/xx/2018, enquanto tentava reservar um ti...  \n",
              "4  Meu neto me dê cheque por {$ 1600,00} Eu depos...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id_reclamacao</th>\n",
              "      <th>data_abertura</th>\n",
              "      <th>categoria</th>\n",
              "      <th>descricao_reclamacao</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21067</th>\n",
              "      <td>3094545</td>\n",
              "      <td>2018-12-07T12:00:00-05:00</td>\n",
              "      <td>Cartão de crédito / Cartão pré-pago</td>\n",
              "      <td>Depois de ser um cliente de cartão de persegui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21068</th>\n",
              "      <td>3091984</td>\n",
              "      <td>2018-12-05T12:00:00-05:00</td>\n",
              "      <td>Roubo / Relatório de disputa</td>\n",
              "      <td>Na quarta -feira, xx/xx/xxxx, liguei para o Ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21069</th>\n",
              "      <td>3133355</td>\n",
              "      <td>2019-01-25T12:00:00-05:00</td>\n",
              "      <td>Roubo / Relatório de disputa</td>\n",
              "      <td>Não estou familiarizado com o XXXX Pay e não e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21070</th>\n",
              "      <td>3110963</td>\n",
              "      <td>2018-12-27T12:00:00-05:00</td>\n",
              "      <td>Outros</td>\n",
              "      <td>Eu tive crédito impecável por 30 anos. Eu tive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21071</th>\n",
              "      <td>2001189</td>\n",
              "      <td>2016-07-06T12:00:00-05:00</td>\n",
              "      <td>Outros</td>\n",
              "      <td>Mais de 10 anos atrás, encerrei minhas contas ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id_reclamacao              data_abertura  \\\n",
              "21067        3094545  2018-12-07T12:00:00-05:00   \n",
              "21068        3091984  2018-12-05T12:00:00-05:00   \n",
              "21069        3133355  2019-01-25T12:00:00-05:00   \n",
              "21070        3110963  2018-12-27T12:00:00-05:00   \n",
              "21071        2001189  2016-07-06T12:00:00-05:00   \n",
              "\n",
              "                                 categoria  \\\n",
              "21067  Cartão de crédito / Cartão pré-pago   \n",
              "21068         Roubo / Relatório de disputa   \n",
              "21069         Roubo / Relatório de disputa   \n",
              "21070                               Outros   \n",
              "21071                               Outros   \n",
              "\n",
              "                                    descricao_reclamacao  \n",
              "21067  Depois de ser um cliente de cartão de persegui...  \n",
              "21068  Na quarta -feira, xx/xx/xxxx, liguei para o Ch...  \n",
              "21069  Não estou familiarizado com o XXXX Pay e não e...  \n",
              "21070  Eu tive crédito impecável por 30 anos. Eu tive...  \n",
              "21071  Mais de 10 anos atrás, encerrei minhas contas ...  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21072 entries, 0 to 21071\n",
            "Data columns (total 4 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   id_reclamacao         21072 non-null  int64 \n",
            " 1   data_abertura         21072 non-null  object\n",
            " 2   categoria             21072 non-null  object\n",
            " 3   descricao_reclamacao  21072 non-null  object\n",
            "dtypes: int64(1), object(3)\n",
            "memory usage: 658.6+ KB\n"
          ]
        }
      ],
      "source": [
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "categoria\n",
              "Serviços de conta bancária             5161\n",
              "Cartão de crédito / Cartão pré-pago    5006\n",
              "Roubo / Relatório de disputa           4822\n",
              "Hipotecas / Empréstimos                3850\n",
              "Outros                                 2233\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[\"categoria\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___\n",
        "#### **Experimentos realizados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Controle de Performance dos Experimentos**\n",
        "\n",
        "A variável a seguir foi definida para realizar o controle dos experimentos, ou seja, a cada experimento feito, iremos incrementar o valor de i (i += 1) e, em seguida, apresentar os valores do modelo treinado na seção."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "i: int = 0\n",
        "results: dict = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 00**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK)\n",
        "- LEMMATIZE (ALL)\n",
        "- COUNT_VECTORIZER (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "25cBRwGAw8-1"
      },
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"count_vectorizer\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7274240481843449, 'recall': 0.7249430523917996, 'f1-score': 0.72417155191262, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9028120908594506, 'recall': 0.9028094153378892, 'f1-score': 0.9027825477411877, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8839674550982918, 'recall': 0.8840167046317388, 'f1-score': 0.8834091588588696, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 01**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- COUNT_VECTORIZER (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"count_vectorizer\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.731519833974445, 'recall': 0.7317767653758542, 'f1-score': 0.7297681461565174, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9001494000798428, 'recall': 0.9001518602885346, 'f1-score': 0.9001464481723435, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8815038943769329, 'recall': 0.8817388003037205, 'f1-score': 0.8812424375073433, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 02**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK + SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- COUNT_VECTORIZER (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"count_vectorizer\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7287218355287862, 'recall': 0.7291192103264996, 'f1-score': 0.7275672840716497, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.8989939588750506, 'recall': 0.8990129081245254, 'f1-score': 0.8989977457577429, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8814934825232511, 'recall': 0.8817388003037205, 'f1-score': 0.8811965910536949, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 03**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK)\n",
        "- LEMMATIZE (ALL)\n",
        "- COUNT_VECTORIZER (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"count_vectorizer\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7228488258024449, 'recall': 0.7209567198177677, 'f1-score': 0.7199297377542196, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9100935779604845, 'recall': 0.9102126044039484, 'f1-score': 0.9101018408208321, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8795352870993577, 'recall': 0.8796507213363706, 'f1-score': 0.8791310254528112, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 04**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- COUNT_VECTORIZER (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"count_vectorizer\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.725878784040775, 'recall': 0.7262718299164769, 'f1-score': 0.7243966262052767, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.912356970270501, 'recall': 0.9124905087319666, 'f1-score': 0.9123818089139148, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.880231180609849, 'recall': 0.8804100227790432, 'f1-score': 0.8799272235517006, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 05**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK + SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- COUNT_VECTORIZER (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"count_vectorizer\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7254063369933709, 'recall': 0.7258921791951405, 'f1-score': 0.7243699905974461, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9125890380960586, 'recall': 0.9126803340926348, 'f1-score': 0.9126079504151651, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8814614632056513, 'recall': 0.8815489749430524, 'f1-score': 0.8810646208784726, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 06**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tf\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7590274565853553, 'recall': 0.7450645406226272, 'f1-score': 0.7482082107210463, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9077315454988181, 'recall': 0.907744874715262, 'f1-score': 0.9076336481904554, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9007070072303339, 'recall': 0.9007213363705391, 'f1-score': 0.9006184889250168, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 07**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tf\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7483573957813439, 'recall': 0.7374715261958997, 'f1-score': 0.7400768862841659, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9082737496679834, 'recall': 0.9083143507972665, 'f1-score': 0.9082281880330897, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9023986205478282, 'recall': 0.9024297646165528, 'f1-score': 0.9023363145474079, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 08**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK + SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tf\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.756240463779386, 'recall': 0.7439255884586181, 'f1-score': 0.7465846023691456, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.908849115843669, 'recall': 0.908883826879271, 'f1-score': 0.9087923646224497, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9027973410789459, 'recall': 0.9028094153378892, 'f1-score': 0.9027054879826875, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 09**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"tf\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.748786843797808, 'recall': 0.7477220956719818, 'f1-score': 0.7465592866114322, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.905844691774582, 'recall': 0.90584662110858, 'f1-score': 0.9057257034864319, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8997470330696032, 'recall': 0.8997722095671982, 'f1-score': 0.8996140087327708, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 10**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"tf\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7481871730493928, 'recall': 0.7425968109339408, 'f1-score': 0.7385245136427945, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9057893876354692, 'recall': 0.90584662110858, 'f1-score': 0.9057423810309457, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8997333134269375, 'recall': 0.8997722095671982, 'f1-score': 0.8996281233860111, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 11**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK + SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"tf\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7584599100268778, 'recall': 0.7471526195899773, 'f1-score': 0.7494943367732017, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9063750998630971, 'recall': 0.9064160971905847, 'f1-score': 0.9063047041515369, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8993636215452142, 'recall': 0.8993925588458618, 'f1-score': 0.8992392170677924, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 12**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK)\n",
        "- LEMMATIZE (ALL)\n",
        "- TFIDF (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7619915545837148, 'recall': 0.7536066818526955, 'f1-score': 0.754989910092383, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9099561227691831, 'recall': 0.909832953682612, 'f1-score': 0.909785976636578, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9020817743972833, 'recall': 0.9020501138952164, 'f1-score': 0.9019787234789474, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 13**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TFID (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7591868103295649, 'recall': 0.7462034927866363, 'f1-score': 0.7489439636636186, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9141233672722235, 'recall': 0.914009111617312, 'f1-score': 0.9139746912547716, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9043750532478413, 'recall': 0.9043280182232346, 'f1-score': 0.9042573739009363, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 14**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK + SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TFID (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7559974222862864, 'recall': 0.7443052391799544, 'f1-score': 0.7466467608154437, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9137564014762783, 'recall': 0.9136294608959757, 'f1-score': 0.913596097460349, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9034597742626403, 'recall': 0.9033788914198937, 'f1-score': 0.9033275555954082, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 15**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK)\n",
        "- LEMMATIZE (ALL)\n",
        "- TFID (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"nltk\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7520347131604599, 'recall': 0.7441154138192863, 'f1-score': 0.7452069215535543, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9039861202838666, 'recall': 0.9037585421412301, 'f1-score': 0.9035667005634038, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8990904193098319, 'recall': 0.8990129081245254, 'f1-score': 0.8988995684950388, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 16**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TFID (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7584931015913955, 'recall': 0.7460136674259681, 'f1-score': 0.7484446372048715, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9058310364257547, 'recall': 0.9056567957479119, 'f1-score': 0.9054387880693512, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.8999936930515755, 'recall': 0.8999620349278664, 'f1-score': 0.8998154848339923, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 17**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (NLTK + SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TF (BIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=2, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"all\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7556247566385215, 'recall': 0.7465831435079726, 'f1-score': 0.7480489244338642, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9055919370416847, 'recall': 0.9054669703872438, 'f1-score': 0.9052447891046912, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9005444440093939, 'recall': 0.9005315110098709, 'f1-score': 0.9003900101216744, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Incrementa o contador de experimentos\n",
        "i += 1\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[f\"{str(i).zfill(2)}\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[f\"{str(i).zfill(2)}\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[f\"{str(i).zfill(2)}\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[f\"{str(i).zfill(2)}\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no experimento 18**\n",
        "\n",
        "- START_CLIENT \n",
        "- CLASSIFY_TEST (GPT-4, GPT-4O-MINI, GPT-3.5-TURBO e SABIA-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Categoria esperada: Cartão de crédito / Cartão pré-pago\n",
            "GPT-4O: {\"texto\": \"Atualizei meu cartão xxxx xxxx em xx/xx/2018 e fui informado pelo agente que fez a atualização que minha data de aniversário não mudaria. Ele virou o agente me dando as informações erradas para atualizar a conta. Xxxx alterou minha data de aniversário de xx/xx/xxxx para xx/xx/xxxx sem meu consentimento! XXXX tem a gravação do agente que me enganou.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "GPT-4O-MINI: {\"texto\": \"Atualizei meu cartão xxxx xxxx em xx/xx/2018 e fui informado pelo agente que fez a atualização que minha data de aniversário não mudaria. Ele virou o agente me dando as informações erradas para atualizar a conta. Xxxx alterou minha data de aniversário de xx/xx/xxxx para xx/xx/xxxx sem meu consentimento! XXXX tem a gravação do agente que me enganou.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "GPT-3.5-TURBO: {\"texto\": \"Atualizei meu cartão xxxx xxxx em xx/xx/2018 e fui informado pelo agente que fez a atualização que minha data de aniversário não mudaria. Ele virou o agente me dando as informações erradas para atualizar a conta. Xxxx alterou minha data de aniversário de xx/xx/xxxx para xx/xx/xxxx sem meu consentimento! XXXX tem a gravação do agente que me enganou.\", \"categoria\": \"roubo ou relatório de disputa\"}\n",
            "SABIA-3: {\"texto\": \"Atualizei meu cartão xxxx xxxx em xx/xx/2018 e fui informado pelo agente que fez a atualização que minha data de aniversário não mudaria. Ele virou o agente me dando as informações erradas para atualizar a conta. Xxxx alterou minha data de aniversário de xx/xx/xxxx para xx/xx/xxxx sem meu consentimento! XXXX tem a gravação do agente que me enganou.\", \"categoria\": \"roubo ou relatório de disputa\"}\n",
            "\n",
            "Categoria esperada: Hipotecas / Empréstimos\n",
            "GPT-4O: {\"texto\": \"Bom dia, meu nome é xxxx xxxx e agradeço se você puder me ajudar a acabar com os serviços de membro do cartão bancário. Em 2018, escrevi para Chase solicitar verificação da dívida e o que eles me enviaram uma declaração que não é aceitável. Estou pedindo ao banco que valide a dívida. Em vez disso, recebi e -mails todos os meses, tentando coletar uma dívida. Tenho o direito de conhecer essas informações como consumidor. Conta do Chase # xxxx xxxx xxxx xxxx Obrigado antecipadamente pela sua ajuda.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "GPT-4O-MINI: {\"texto\": \"Bom dia, meu nome é xxxx xxxx e agradeço se você puder me ajudar a acabar com os serviços de membro do cartão bancário. Em 2018, escrevi para Chase solicitar verificação da dívida e o que eles me enviaram uma declaração que não é aceitável. Estou pedindo ao banco que valide a dívida. Em vez disso, recebi e -mails todos os meses, tentando coletar uma dívida. Tenho o direito de conhecer essas informações como consumidor. Conta do Chase # xxxx xxxx xxxx xxxx Obrigado antecipadamente pela sua ajuda.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "GPT-3.5-TURBO: {\"texto\": \"Bom dia, meu nome é xxxx xxxx e agradeço se você puder me ajudar a acabar com os serviços de membro do cartão bancário. Em 2018, escrevi para Chase solicitar verificação da dívida e o que eles me enviaram uma declaração que não é aceitável. Estou pedindo ao banco que valide a dívida. Em vez disso, recebi e -mails todos os meses, tentando coletar uma dívida. Tenho o direito de conhecer essas informações como consumidor. Conta do Chase # xxxx xxxx xxxx xxxx Obrigado antecipadamente pela sua ajuda.\", \"categoria\": \"serviços de conta bancária\"}\n",
            "SABIA-3: {\"texto\": \"Bom dia, meu nome é xxxx xxxx e agradeço se você puder me ajudar a acabar com os serviços de membro do cartão bancário. Em 2018, escrevi para Chase solicitar verificação da dívida e o que eles me enviaram uma declaração que não é aceitável. Estou pedindo ao banco que valide a dívida. Em vez disso, recebi e-mails todos os meses, tentando coletar uma dívida. Tenho o direito de conhecer essas informações como consumidor. Conta do Chase # xxxx xxxx xxxx xxxx Obrigado antecipadamente pela sua ajuda.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "\n",
            "Categoria esperada: Roubo / Relatório de disputa\n",
            "GPT-4O: {\"texto\": \"Xxxx xxxx um sofá, assento de amor, mesa e cadeiras e nunca foi entregue. Cartão de débito cobrado {$ 2400.00}. O Banco diz que o Visa negou reivindicação, não temos móveis nem dinheiro.\", \"categoria\": \"roubo ou relatório de disputa\"}\n",
            "GPT-4O-MINI: {\"texto\": \"Xxxx xxxx um sofá, assento de amor, mesa e cadeiras e nunca foi entregue. Cartão de débito cobrado {$ 2400.00}. O Banco diz que o Visa negou reivindicação, não temos móveis nem dinheiro.\", \"categoria\": \"roubo ou relatório de disputa\"}\n",
            "GPT-3.5-TURBO: {\"texto\": \"Xxxx xxxx um sofá, assento de amor, mesa e cadeiras e nunca foi entregue. Cartão de débito cobrado {$ 2400.00}. O Banco diz que o Visa negou reivindicação, não temos móveis nem dinheiro.\", \"categoria\": \"roubo ou relatório de disputa\"}\n",
            "SABIA-3: {\"texto\": \"Xxxx xxxx um sofá, assento de amor, mesa e cadeiras e nunca foi entregue. Cartão de débito cobrado {$ 2400.00}. O Banco diz que o Visa negou reivindicação, não temos móveis nem dinheiro.\", \"categoria\": \"roubo ou relatório de disputa\"}\n",
            "\n",
            "Categoria esperada: Serviços de conta bancária\n",
            "GPT-4O: {\"texto\": \"Abri a conta de poupança para o bônus {$ 25,00}. Eu deveria receber o bônus {$ 25,00} após três transferências consecutivas de automóveis da verificação para a economia. Percebo em xx/xx/2019 que a transferência automática foi cancelada por fundos insuficientes na minha conta da minha verificação. Portanto, coloquei fundos suficientes em minha conta no XX/XX/2019 solicitou que a equipe executiva reativasse minha transferência automática para o mês de XXXX. Embora a sra. XXXX tenha me procurado do escritório executivo, ela não tentou resolver minhas preocupações (caso # xxxx).\", \"categoria\": \"serviços de conta bancária\"}\n",
            "GPT-4O-MINI: {\"texto\": \"Abri a conta de poupança para o bônus {$ 25,00}. Eu deveria receber o bônus {$ 25,00} após três transferências consecutivas de automóveis da verificação para a economia. Percebo em xx/xx/2019 que a transferência automática foi cancelada por fundos insuficientes na minha conta da minha verificação. Portanto, coloquei fundos suficientes em minha conta no XX/XX/2019 solicitou que a equipe executiva reativasse minha transferência automática para o mês de XXXX. Embora a sra. XXXX tenha me procurado do escritório executivo, ela não tentou resolver minhas preocupações (caso # xxxx).\", \"categoria\": \"serviços de conta bancária\"}\n",
            "GPT-3.5-TURBO: {\"texto\": \"Abri a conta de poupança para o bônus {$ 25,00}. Eu deveria receber o bônus {$ 25,00} após três transferências consecutivas de automóveis da verificação para a economia. Percebo em xx/xx/2019 que a transferência automática foi cancelada por fundos insuficientes na minha conta da minha verificação. Portanto, coloquei fundos suficientes em minha conta no XX/XX/2019 solicitou que a equipe executiva reativasse minha transferência automática para o mês de XXXX. Embora a sra. XXXX tenha me procurado do escritório executivo, ela não tentou resolver minhas preocupações (caso # xxxx).\", \"categoria\": \"serviços de conta bancária\"}\n",
            "SABIA-3: ```json\n",
            "{\n",
            "  \"texto\": \"Abri a conta de poupança para o bônus {$ 25,00}. Eu deveria receber o bônus {$ 25,00} após três transferências consecutivas de automóveis da verificação para a economia. Percebo em xx/xx/2019 que a transferência automática foi cancelada por fundos insuficientes na minha conta da minha verificação. Portanto, coloquei fundos suficientes em minha conta no XX/XX/2019 solicitou que a equipe executiva reativasse minha transferência automática para o mês de XXXX. Embora a sra. XXXX tenha me procurado do escritório executivo, ela não tentou resolver minhas preocupações (caso # xxxx).\",\n",
            "  \"categoria\": \"serviços de conta bancária\"\n",
            "}\n",
            "```\n",
            "\n",
            "Categoria esperada: Outros\n",
            "GPT-4O: {\"texto\": \"Fiz uma compra de {$ 260,00} em xx/xx/xxxx. Fiz pagamentos de {$ 160,00} em xx/xx/xxxx e {$ 260,00} em xx/xx/xxxx. O pagamento mínimo foi {$ 140,00}. A data de fechamento era xx/xx/xxxx (consulte a instrução anexada). Essa instrução (xx/xx/xxxx) mostra que eu tinha um excelente saldo de compra de {$ 230,00} em xx/xx/xxxx. Eu incluí a declaração dos meses anteriores para mostrar que não havia outras compras anteriores à de XX/XX/XXXX.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "GPT-4O-MINI: {\"texto\": \"Fiz uma compra de {$ 260,00} em xx/xx/xxxx. Fiz pagamentos de {$ 160,00} em xx/xx/xxxx e {$ 260,00} em xx/xx/xxxx. O pagamento mínimo foi {$ 140,00}. A data de fechamento era xx/xx/xxxx (consulte a instrução anexada). Essa instrução (xx/xx/xxxx) mostra que eu tinha um excelente saldo de compra de {$ 230,00} em xx/xx/xxxx. Eu incluí a declaração dos meses anteriores para mostrar que não havia outras compras anteriores à de XX/XX/XXXX.\", \"categoria\": \"cartão de crédito ou cartão pré-pago\"}\n",
            "GPT-3.5-TURBO: {\"texto\": \"Fiz uma compra de {$ 260,00} em xx/xx/xxxx. Fiz pagamentos de {$ 160,00} em xx/xx/xxxx e {$ 260,00} em xx/xx/xxxx. O pagamento mínimo foi {$ 140,00}. A data de fechamento era xx/xx/xxxx (consulte a instrução anexada). Essa instrução (xx/xx/xxxx) mostra que eu tinha um excelente saldo de compra de {$ 230,00} em xx/xx/xxxx. Eu incluí a declaração dos meses anteriores para mostrar que não havia outras compras anteriores à de XX/XX/XXXX.\", \"categoria\": \"serviços de conta bancária\"}\n",
            "SABIA-3: {\"texto\": \"Fiz uma compra de {$ 260,00} em xx/xx/xxxx. Fiz pagamentos de {$ 160,00} em xx/xx/xxxx e {$ 260,00} em xx/xx/xxxx. O pagamento mínimo foi {$ 140,00}. A data de fechamento era xx/xx/xxxx (consulte a instrução anexada). Essa instrução (xx/xx/xxxx) mostra que eu tinha um excelente saldo de compra de {$ 230,00} em xx/xx/xxxx. Eu incluí a declaração dos meses anteriores para mostrar que não havia outras compras anteriores à de XX/XX/XXXX.\", \"categoria\": \"cartão de crédito\"}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definição das chaves de autenticação e URL do modelo\n",
        "API_KEY_GPT: str = os.getenv(\"GPT_ACCESS_KEY\")\n",
        "API_KEY_MARITACA: str = os.getenv(\"MARITACA_ACCESS_KEY\")\n",
        "BASE_URL: str = \"https://chat.maritaca.ai/api\" \n",
        "\n",
        "# Inicialização dos clients GPT e MARITACA\n",
        "client_gpt = start_client(model=\"gpt-4o-mini\", api_key=API_KEY_GPT)\n",
        "client_maritaca = start_client(model=\"sabia-3\", api_key=API_KEY_MARITACA, base_url=BASE_URL)\n",
        "\n",
        "# Frases a serem classificadas com o uso dos LLMs\n",
        "texts : dict = {\n",
        "    \"Cartão de crédito / Cartão pré-pago\" : \"Atualizei meu cartão xxxx xxxx em xx/xx/2018 e fui informado pelo agente que fez a atualização que minha data de aniversário não mudaria. Ele virou o agente me dando as informações erradas para atualizar a conta. Xxxx alterou minha data de aniversário de xx/xx/xxxx para xx/xx/xxxx sem meu consentimento! XXXX tem a gravação do agente que me enganou.\",\n",
        "    \"Hipotecas / Empréstimos\" : \"Bom dia, meu nome é xxxx xxxx e agradeço se você puder me ajudar a acabar com os serviços de membro do cartão bancário. Em 2018, escrevi para Chase solicitar verificação da dívida e o que eles me enviaram uma declaração que não é aceitável. Estou pedindo ao banco que valide a dívida. Em vez disso, recebi e -mails todos os meses, tentando coletar uma dívida. Tenho o direito de conhecer essas informações como consumidor. Conta do Chase # xxxx xxxx xxxx xxxx Obrigado antecipadamente pela sua ajuda.\",\n",
        "    \"Roubo / Relatório de disputa\" : \"Xxxx xxxx um sofá, assento de amor, mesa e cadeiras e nunca foi entregue. Cartão de débito cobrado {$ 2400.00}. O Banco diz que o Visa negou reivindicação, não temos móveis nem dinheiro.\",\n",
        "    \"Serviços de conta bancária\" : \"Abri a conta de poupança para o bônus {$ 25,00}. Eu deveria receber o bônus {$ 25,00} após três transferências consecutivas de automóveis da verificação para a economia. Percebo em xx/xx/2019 que a transferência automática foi cancelada por fundos insuficientes na minha conta da minha verificação. Portanto, coloquei fundos suficientes em minha conta no XX/XX/2019 solicitou que a equipe executiva reativasse minha transferência automática para o mês de XXXX. Embora a sra. XXXX tenha me procurado do escritório executivo, ela não tentou resolver minhas preocupações (caso # xxxx).\",\n",
        "    \"Outros\" : \"Fiz uma compra de {$ 260,00} em xx/xx/xxxx. Fiz pagamentos de {$ 160,00} em xx/xx/xxxx e {$ 260,00} em xx/xx/xxxx. O pagamento mínimo foi {$ 140,00}. A data de fechamento era xx/xx/xxxx (consulte a instrução anexada). Essa instrução (xx/xx/xxxx) mostra que eu tinha um excelente saldo de compra de {$ 230,00} em xx/xx/xxxx. Eu incluí a declaração dos meses anteriores para mostrar que não havia outras compras anteriores à de XX/XX/XXXX.\"\n",
        "}\n",
        "\n",
        "# Classificação das frases supracitadas com o uso dos LLMs (GPT-4O, GPT-4O-MINI, GPT-3.5-TURBO e SABIA-3)\n",
        "for key, value in texts.items():\n",
        "    answer_gpt_4: str = str(classify_text(client=client_gpt, model=\"gpt-4o\", text=value))\n",
        "    answer_gpt_4_o_mini: str = str(classify_text(client=client_gpt, model=\"gpt-4o-mini\", text=value))\n",
        "    answer_gpt_3_5_turbo: str = str(classify_text(client=client_gpt, model=\"gpt-3.5-turbo\", text=value))\n",
        "    answer_maritaca: str = str(classify_text(client=client_maritaca, model=\"sabia-3\", text=value))\n",
        "    print(f\"Categoria esperada: {key}\\nGPT-4O: {answer_gpt_4}\\nGPT-4O-MINI: {answer_gpt_4_o_mini}\\nGPT-3.5-TURBO: {answer_gpt_3_5_turbo}\\nSABIA-3: {answer_maritaca}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "___\n",
        "#### Conclusões Finais"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**F1-score do modelo campeão**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo campeão: 13 LOGISTIC_REGRESSION\n",
            "-> F1-Score: 91.4\n"
          ]
        }
      ],
      "source": [
        "# Inicializa o dicionário para armazenar o F1-score dos modelos\n",
        "f1: dict = dict()\n",
        "\n",
        "# Percorre os experimentos realizados\n",
        "for key in results:\n",
        "    # Armazena o i-ésimo F1-score dos modelos DecisionTree, LogisticRegression e SVM\n",
        "    current_decision_tree_f1: float = round(float(results[key][\"DECISION_TREE\"][\"weighted avg\"][\"f1-score\"]) * 100, 2)\n",
        "    current_logistic_regression_f1: float = round(float(results[key][\"LOGISTIC_REGRESSION\"][\"weighted avg\"][\"f1-score\"]) * 100, 2)\n",
        "    current_svm_f1: float = round(float(results[key][\"SVM\"][\"weighted avg\"][\"f1-score\"]) * 100, 2)\n",
        "\n",
        "    # F1-score do DecisionTree superior ao LogisticRegression e SVM\n",
        "    if current_decision_tree_f1 > current_logistic_regression_f1 and current_decision_tree_f1 > current_svm_f1:\n",
        "        f1[f\"{key} DECISION_TREE\"] = current_decision_tree_f1\n",
        "    \n",
        "    # F1-score do LogisticRegression superior ao DecisionTree e SVM\n",
        "    if current_logistic_regression_f1 > current_decision_tree_f1 and current_logistic_regression_f1 > current_svm_f1:\n",
        "        f1[f\"{key} LOGISTIC_REGRESSION\"] = current_logistic_regression_f1\n",
        "    \n",
        "    # F1-score do SVM superior ao DecisionTree e LogisticRegression\n",
        "    if current_svm_f1 > current_decision_tree_f1 and current_svm_f1 > current_logistic_regression_f1:\n",
        "        f1[f\"{key} SVM\"] = current_svm_f1\n",
        "\n",
        "# F1-score máximo após avaliação dos modelos\n",
        "max_f1: float = float(max(f1.values()))\n",
        "\n",
        "# Definição do modelo campeão\n",
        "champion: str = str([key for key, value in f1.items() if float(value) == max_f1][0])\n",
        "print(f\"Modelo campeão: {champion}\")\n",
        "print(f\"-> F1-Score: {f1.get(champion)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Funções aplicadas no modelo campeão**\n",
        "\n",
        "- PREPROCESSING\n",
        "- REMOVE_STOP_WORDS (SPACY)\n",
        "- LEMMATIZE (ALL)\n",
        "- TFID (UNIGRAMA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definição dos conjuntos de treino (75%) e teste (25%)\n",
        "dataset_train, dataset_test = train_test_split(dataset, train_size=0.75, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de treinamento\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_train[\"descricao_reclamacao\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_train[\"descricao_reclamacao_lemmatize_all\"] = dataset_train[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de treinamento\n",
        "vect = vectorize(custom_ngram=1, function=\"tfid\")\n",
        "vect.fit(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "\n",
        "x_train = vect.transform(dataset_train[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_train = dataset_train[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pré-processamento e remoção de stop words do conjunto de teste\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: preprocessing_text(text=x))\n",
        "dataset_test[\"descricao_reclamacao\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: remove_stop_words(text=x, mode=\"spacy\"))\n",
        "dataset_test[\"descricao_reclamacao_lemmatize_all\"] = dataset_test[\"descricao_reclamacao\"].apply(lambda x: lemmatize(text=x, mode=\"all\"))\n",
        "\n",
        "# Vetorização do conjunto de teste\n",
        "x_test = vect.transform(dataset_test[\"descricao_reclamacao_lemmatize_all\"])\n",
        "y_test = dataset_test[\"categoria\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DECISION TREE: {'precision': 0.7591868103295649, 'recall': 0.7462034927866363, 'f1-score': 0.7489439636636186, 'support': 5268.0}\n",
            "LOGISTIC REGRESSION: {'precision': 0.9141233672722235, 'recall': 0.914009111617312, 'f1-score': 0.9139746912547716, 'support': 5268.0}\n",
            "SUPPORT VECTOR MACHINE: {'precision': 0.9043750532478413, 'recall': 0.9043280182232346, 'f1-score': 0.9042573739009363, 'support': 5268.0}\n"
          ]
        }
      ],
      "source": [
        "# Treinamento, predição e avaliação dos modelos\n",
        "experiment  = fit_predict_evaluate_models(x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "\n",
        "# Adiciona os resultados experimentos ao dicionário de resultados\n",
        "results[\"13\"] = experiment\n",
        "\n",
        "# Apresenta os resultados para cada modelo do experimento\n",
        "print(\"DECISION TREE:\", results[\"13\"][\"DECISION_TREE\"][\"weighted avg\"])\n",
        "print(\"LOGISTIC REGRESSION:\", results[\"13\"][\"LOGISTIC_REGRESSION\"][\"weighted avg\"])\n",
        "print(\"SUPPORT VECTOR MACHINE:\", results[\"13\"][\"SVM\"][\"weighted avg\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Conforme apresentado acima, o modelo campeão derivou do 13° experimento utilizando a técnica de regressão logística. No experimento, utilizamos a função de pré-processamento, remoção de stop words do SPACY, lematização de todas as palavras e vetorização TFID e obtivemos um F1-score de aproximadamente 91.4%.\n",
        "\n",
        "Sobre a aplicação dos modelos generativos, entendemos que há oportunidades para explorar outras abordagens, como por exemplo, a utilização de técnicas como o fine tuning para especializar o modelo em um determinado contexto. Entretanto, devido ao custo dos experimentos, optamos neste momento por seguir com uma visão mais simples da aplicação, onde classificamos apenas 5 chamados."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
